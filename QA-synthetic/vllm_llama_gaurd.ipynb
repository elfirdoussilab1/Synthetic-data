{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29f7734-fd92-4229-af0e-7ccd2155ad55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80925996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Verfier is used to check for the quality of synethic QA using llama-guard-3-8B\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b02aae-7f7d-4ae7-8bdc-4f9db313eca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-Guard-3-8B'\n",
    "out_dir = \"output\"\n",
    "df_data = pd.read_json(f\"{out_dir}/all_responses.json\")\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4e130f6-84df-48ad-8cc9-89973f4f84d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c676c-e3bc-4257-a12e-99a18f4be4db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = LLM(model=model_name, max_model_len=4096, tensor_parallel_size=4, gpu_memory_utilization=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "953c17c5-426c-470a-b28f-ddb77e58f05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0.9, top_p=0.97, max_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e15a9b1a-6917-43cc-94f7-63cc93342dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_resp(msg):\n",
    "    assistant_content = msg[1][\"content\"]\n",
    "    resp = assistant_content[assistant_content.find(\"Agent:\\n\")+7:]\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1380c63e-0be6-4ea1-81bd-8ca3e7591f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset = df_data #.sample(100,random_state=10)\n",
    "formatted = [tokenizer.apply_chat_template([{\"content\":row[\"prompt\"],\"role\":\"user\"},{\"content\":extract_resp(row[\"messages\"]),\"role\":\"assistant\"}], tokenize=False, add_generation_prompt=True) for i, row in subset.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b469ea-b2a9-4846-9c44-dc743ce869dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(formatted[76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8749d-6925-4c1d-822b-59d25a82c308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = llm.generate(formatted, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08992168-0c61-4d6f-b36f-1bcd3591fe12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_out(row, out):\n",
    "        if \"unsafe\" in out:\n",
    "            row[\"Guard\"] = \"unsafe\"\n",
    "        elif \"safe\" in out:\n",
    "            row[\"Guard\"] = \"safe\"\n",
    "        else:\n",
    "            row[\"Guard\"] = \"none\"\n",
    "        return row\n",
    "\n",
    "subset_out = pd.DataFrame(columns = subset.columns)\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for (i, row), out in tqdm(zip(subset.iterrows(),outputs),total=len(outputs),desc=\"post generation processing\"):\n",
    "        res = out.outputs[0].text.lower()\n",
    "        new_row = set_out(row, res)\n",
    "        new_row[\"Guard_prompt\"] = out.prompt\n",
    "        subset_out = pd.concat([subset_out, pd.DataFrame([new_row])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86513aeb-2891-4a1a-8b54-0ad92fb1a73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_out = subset_out[~(subset_out[\"llm_judge\"]==\"none\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88848058-7e94-4eb9-b7e2-81653f7775a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_out[\"Guard\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cdb1e2-a50d-4268-b735-db23dd08bc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_out[\"safe_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9abfe-c8b5-472f-83e4-72e06c8aeb47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_out[\"llm_judge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "533ff94b-a608-4b29-9976-dc501fd128c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_out.to_json(f\"{out_dir}/full_responses_guard.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
